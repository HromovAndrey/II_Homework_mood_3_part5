{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":60892,"databundleVersionId":6989718,"sourceType":"competition"}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/homework-mood-3-part-5?scriptVersionId=189492982\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-23T18:53:43.319618Z","iopub.execute_input":"2024-07-23T18:53:43.320117Z","iopub.status.idle":"2024-07-23T18:53:43.32943Z","shell.execute_reply.started":"2024-07-23T18:53:43.320057Z","shell.execute_reply":"2024-07-23T18:53:43.327897Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s3e25/sample_submission.csv\n/kaggle/input/playground-series-s3e25/train.csv\n/kaggle/input/playground-series-s3e25/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import median_absolute_error\nimport lightgbm as lgb\nimport joblib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.331731Z","iopub.execute_input":"2024-07-23T18:53:43.332696Z","iopub.status.idle":"2024-07-23T18:53:43.34784Z","shell.execute_reply.started":"2024-07-23T18:53:43.332545Z","shell.execute_reply":"2024-07-23T18:53:43.346621Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/playground-series-s3e25/train.csv')\ntest_data = pd.read_csv('/kaggle/input/playground-series-s3e25/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.349823Z","iopub.execute_input":"2024-07-23T18:53:43.350228Z","iopub.status.idle":"2024-07-23T18:53:43.404813Z","shell.execute_reply.started":"2024-07-23T18:53:43.350177Z","shell.execute_reply":"2024-07-23T18:53:43.403771Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"train_data = train_data.drop(columns=['id'])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.406044Z","iopub.execute_input":"2024-07-23T18:53:43.406415Z","iopub.status.idle":"2024-07-23T18:53:43.412457Z","shell.execute_reply.started":"2024-07-23T18:53:43.406384Z","shell.execute_reply":"2024-07-23T18:53:43.411325Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"y = train_data['Hardness']\nX = train_data.drop(columns='Hardness')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.415071Z","iopub.execute_input":"2024-07-23T18:53:43.41584Z","iopub.status.idle":"2024-07-23T18:53:43.42645Z","shell.execute_reply.started":"2024-07-23T18:53:43.415806Z","shell.execute_reply":"2024-07-23T18:53:43.425259Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, \n                                                  test_size=0.2, \n                                                  random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.42769Z","iopub.execute_input":"2024-07-23T18:53:43.428047Z","iopub.status.idle":"2024-07-23T18:53:43.441234Z","shell.execute_reply.started":"2024-07-23T18:53:43.428018Z","shell.execute_reply":"2024-07-23T18:53:43.440058Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = X.select_dtypes(include=['object']).columns","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.442787Z","iopub.execute_input":"2024-07-23T18:53:43.443274Z","iopub.status.idle":"2024-07-23T18:53:43.451847Z","shell.execute_reply.started":"2024-07-23T18:53:43.443233Z","shell.execute_reply":"2024-07-23T18:53:43.450705Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"numeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.453444Z","iopub.execute_input":"2024-07-23T18:53:43.454441Z","iopub.status.idle":"2024-07-23T18:53:43.465966Z","shell.execute_reply.started":"2024-07-23T18:53:43.454394Z","shell.execute_reply":"2024-07-23T18:53:43.464484Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"categorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.467568Z","iopub.execute_input":"2024-07-23T18:53:43.467972Z","iopub.status.idle":"2024-07-23T18:53:43.481442Z","shell.execute_reply.started":"2024-07-23T18:53:43.467939Z","shell.execute_reply":"2024-07-23T18:53:43.48024Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.483943Z","iopub.execute_input":"2024-07-23T18:53:43.484366Z","iopub.status.idle":"2024-07-23T18:53:43.495441Z","shell.execute_reply.started":"2024-07-23T18:53:43.484335Z","shell.execute_reply":"2024-07-23T18:53:43.493584Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"X_train_preprocessed = preprocessor.fit_transform(X_train)\nX_val_preprocessed = preprocessor.transform(X_val)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.497845Z","iopub.execute_input":"2024-07-23T18:53:43.498443Z","iopub.status.idle":"2024-07-23T18:53:43.542526Z","shell.execute_reply.started":"2024-07-23T18:53:43.498394Z","shell.execute_reply":"2024-07-23T18:53:43.540753Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    param = {\n        'num_leaves': trial.suggest_int('num_leaves', 20, 30),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n        'n_estimators': trial.suggest_int('n_estimators', 30, 50),\n        'min_child_samples': trial.suggest_int('min_child_samples', 5, 20)\n    }\n    \n    model = lgb.LGBMRegressor(**param)\n    model.fit(X_train_preprocessed, y_train)\n    y_val_pred = model.predict(X_val_preprocessed)\n    val_score = median_absolute_error(y_val, y_val_pred)\n    return val_score","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.543958Z","iopub.execute_input":"2024-07-23T18:53:43.544461Z","iopub.status.idle":"2024-07-23T18:53:43.552382Z","shell.execute_reply.started":"2024-07-23T18:53:43.544418Z","shell.execute_reply":"2024-07-23T18:53:43.550994Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:43.554238Z","iopub.execute_input":"2024-07-23T18:53:43.554632Z","iopub.status.idle":"2024-07-23T18:53:51.92376Z","shell.execute_reply.started":"2024-07-23T18:53:43.554601Z","shell.execute_reply":"2024-07-23T18:53:51.922315Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stderr","text":"[I 2024-07-23 18:53:43,561] A new study created in memory with name: no-name-c12796e7-1932-4c6d-81ca-1763ebf7d384\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:43,687] Trial 0 finished with value: 1.0046813292264356 and parameters: {'num_leaves': 22, 'learning_rate': 0.02339572985471249, 'n_estimators': 37, 'min_child_samples': 19}. Best is trial 0 with value: 1.0046813292264356.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001798 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001783 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:43,835] Trial 1 finished with value: 1.322754732629174 and parameters: {'num_leaves': 21, 'learning_rate': 0.0006178995215687864, 'n_estimators': 44, 'min_child_samples': 17}. Best is trial 0 with value: 1.0046813292264356.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:43,968] Trial 2 finished with value: 1.3135886945571844 and parameters: {'num_leaves': 26, 'learning_rate': 0.0010527267989081403, 'n_estimators': 34, 'min_child_samples': 6}. Best is trial 0 with value: 1.0046813292264356.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001836 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:44,083] Trial 3 finished with value: 1.2678396091454385 and parameters: {'num_leaves': 24, 'learning_rate': 0.002619879257452361, 'n_estimators': 32, 'min_child_samples': 18}. Best is trial 0 with value: 1.0046813292264356.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:44,211] Trial 4 finished with value: 0.7842501527641037 and parameters: {'num_leaves': 22, 'learning_rate': 0.05363367365205888, 'n_estimators': 37, 'min_child_samples': 15}. Best is trial 4 with value: 0.7842501527641037.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001782 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001794 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:44,363] Trial 5 finished with value: 1.3421679013919556 and parameters: {'num_leaves': 30, 'learning_rate': 0.00018243112220928595, 'n_estimators': 41, 'min_child_samples': 10}. Best is trial 4 with value: 0.7842501527641037.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:44,523] Trial 6 finished with value: 1.2442391956640435 and parameters: {'num_leaves': 30, 'learning_rate': 0.0023993046028640322, 'n_estimators': 45, 'min_child_samples': 15}. Best is trial 4 with value: 0.7842501527641037.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001744 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001767 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:44,641] Trial 7 finished with value: 1.2723633287010827 and parameters: {'num_leaves': 25, 'learning_rate': 0.002458522769223908, 'n_estimators': 32, 'min_child_samples': 13}. Best is trial 4 with value: 0.7842501527641037.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:44,795] Trial 8 finished with value: 1.3363866723419706 and parameters: {'num_leaves': 25, 'learning_rate': 0.00033704632531862325, 'n_estimators': 39, 'min_child_samples': 19}. Best is trial 4 with value: 0.7842501527641037.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001753 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002026 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:44,929] Trial 9 finished with value: 1.3209218114899972 and parameters: {'num_leaves': 25, 'learning_rate': 0.0007903868308130516, 'n_estimators': 36, 'min_child_samples': 15}. Best is trial 4 with value: 0.7842501527641037.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:45,099] Trial 10 finished with value: 0.6833015658684287 and parameters: {'num_leaves': 20, 'learning_rate': 0.09999473129434122, 'n_estimators': 50, 'min_child_samples': 9}. Best is trial 10 with value: 0.6833015658684287.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001815 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001857 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:45,287] Trial 11 finished with value: 0.681823412848843 and parameters: {'num_leaves': 20, 'learning_rate': 0.08644601040711065, 'n_estimators': 50, 'min_child_samples': 9}. Best is trial 11 with value: 0.681823412848843.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:45,517] Trial 12 finished with value: 0.6840662214406195 and parameters: {'num_leaves': 20, 'learning_rate': 0.09064555830225017, 'n_estimators': 50, 'min_child_samples': 8}. Best is trial 11 with value: 0.681823412848843.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002340 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:45,747] Trial 13 finished with value: 0.9702158873426892 and parameters: {'num_leaves': 20, 'learning_rate': 0.018901389791241698, 'n_estimators': 50, 'min_child_samples': 10}. Best is trial 11 with value: 0.681823412848843.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:45,954] Trial 14 finished with value: 1.1042926065869771 and parameters: {'num_leaves': 23, 'learning_rate': 0.0102423385748328, 'n_estimators': 47, 'min_child_samples': 5}. Best is trial 11 with value: 0.681823412848843.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002239 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001795 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:46,130] Trial 15 finished with value: 0.6778488084118497 and parameters: {'num_leaves': 27, 'learning_rate': 0.09796911611509763, 'n_estimators': 48, 'min_child_samples': 10}. Best is trial 15 with value: 0.6778488084118497.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:46,317] Trial 16 finished with value: 1.0769929833245184 and parameters: {'num_leaves': 27, 'learning_rate': 0.011471458121720188, 'n_estimators': 46, 'min_child_samples': 11}. Best is trial 15 with value: 0.6778488084118497.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001939 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:46,496] Trial 17 finished with value: 0.8122245727370878 and parameters: {'num_leaves': 28, 'learning_rate': 0.03767099808632886, 'n_estimators': 43, 'min_child_samples': 7}. Best is trial 15 with value: 0.6778488084118497.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:46,686] Trial 18 finished with value: 1.1320251853788696 and parameters: {'num_leaves': 28, 'learning_rate': 0.0068154761119720315, 'n_estimators': 48, 'min_child_samples': 12}. Best is trial 15 with value: 0.6778488084118497.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001849 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001748 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:46,871] Trial 19 finished with value: 0.8029772752019779 and parameters: {'num_leaves': 28, 'learning_rate': 0.03617154170075776, 'n_estimators': 47, 'min_child_samples': 8}. Best is trial 15 with value: 0.6778488084118497.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:47,036] Trial 20 finished with value: 1.1563964321205589 and parameters: {'num_leaves': 27, 'learning_rate': 0.005933366720738849, 'n_estimators': 41, 'min_child_samples': 13}. Best is trial 15 with value: 0.6778488084118497.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001747 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001770 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:47,206] Trial 21 finished with value: 0.6856515574215085 and parameters: {'num_leaves': 21, 'learning_rate': 0.07764918888388699, 'n_estimators': 49, 'min_child_samples': 9}. Best is trial 15 with value: 0.6778488084118497.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:47,374] Trial 22 finished with value: 0.6713366299663958 and parameters: {'num_leaves': 23, 'learning_rate': 0.09971633555235294, 'n_estimators': 50, 'min_child_samples': 9}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001766 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001742 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:47,548] Trial 23 finished with value: 0.7754509454346648 and parameters: {'num_leaves': 23, 'learning_rate': 0.042477976401362166, 'n_estimators': 48, 'min_child_samples': 7}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:47,713] Trial 24 finished with value: 0.9519639722975115 and parameters: {'num_leaves': 24, 'learning_rate': 0.021333170100842288, 'n_estimators': 45, 'min_child_samples': 11}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001731 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001812 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:47,883] Trial 25 finished with value: 0.7737268406058317 and parameters: {'num_leaves': 26, 'learning_rate': 0.046310541159989456, 'n_estimators': 43, 'min_child_samples': 5}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:48,072] Trial 26 finished with value: 0.7006941658629446 and parameters: {'num_leaves': 23, 'learning_rate': 0.06470097955773185, 'n_estimators': 48, 'min_child_samples': 9}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001848 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001725 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:48,245] Trial 27 finished with value: 0.9126808997529336 and parameters: {'num_leaves': 21, 'learning_rate': 0.023341716313967465, 'n_estimators': 50, 'min_child_samples': 12}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:48,409] Trial 28 finished with value: 0.7015496409391924 and parameters: {'num_leaves': 22, 'learning_rate': 0.062494082184415, 'n_estimators': 46, 'min_child_samples': 10}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001760 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001733 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:48,602] Trial 29 finished with value: 1.0536599257871826 and parameters: {'num_leaves': 29, 'learning_rate': 0.014931183893041582, 'n_estimators': 48, 'min_child_samples': 7}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:48,733] Trial 30 finished with value: 0.9660029271056607 and parameters: {'num_leaves': 24, 'learning_rate': 0.03138345556011912, 'n_estimators': 30, 'min_child_samples': 11}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001918 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:48,899] Trial 31 finished with value: 0.6859210524442179 and parameters: {'num_leaves': 20, 'learning_rate': 0.09399840817312313, 'n_estimators': 50, 'min_child_samples': 9}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:49,062] Trial 32 finished with value: 0.6799055907016562 and parameters: {'num_leaves': 21, 'learning_rate': 0.09876644925764949, 'n_estimators': 49, 'min_child_samples': 8}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001776 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001789 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:49,235] Trial 33 finished with value: 0.8554140195443178 and parameters: {'num_leaves': 21, 'learning_rate': 0.029433840102682334, 'n_estimators': 49, 'min_child_samples': 8}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:49,409] Trial 34 finished with value: 0.730563940879783 and parameters: {'num_leaves': 22, 'learning_rate': 0.05547719204615794, 'n_estimators': 46, 'min_child_samples': 6}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002001 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001861 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:49,567] Trial 35 finished with value: 0.7106871784058661 and parameters: {'num_leaves': 21, 'learning_rate': 0.06439063954079162, 'n_estimators': 44, 'min_child_samples': 6}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:49,741] Trial 36 finished with value: 1.275715033684989 and parameters: {'num_leaves': 22, 'learning_rate': 0.001553672866209458, 'n_estimators': 49, 'min_child_samples': 10}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001765 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:49,923] Trial 37 finished with value: 1.1690362220327577 and parameters: {'num_leaves': 26, 'learning_rate': 0.004680860341633815, 'n_estimators': 47, 'min_child_samples': 8}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:50,099] Trial 38 finished with value: 0.7179060338320762 and parameters: {'num_leaves': 23, 'learning_rate': 0.054065680645400585, 'n_estimators': 49, 'min_child_samples': 14}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001798 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001748 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:50,262] Trial 39 finished with value: 1.342580465835801 and parameters: {'num_leaves': 22, 'learning_rate': 0.00016418496585053773, 'n_estimators': 44, 'min_child_samples': 11}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:50,419] Trial 40 finished with value: 0.6971670985084031 and parameters: {'num_leaves': 24, 'learning_rate': 0.09629182626222714, 'n_estimators': 39, 'min_child_samples': 7}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001791 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001763 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:50,587] Trial 41 finished with value: 0.6865269936475507 and parameters: {'num_leaves': 20, 'learning_rate': 0.07854081310193366, 'n_estimators': 50, 'min_child_samples': 9}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:50,764] Trial 42 finished with value: 0.6760886876661423 and parameters: {'num_leaves': 21, 'learning_rate': 0.09695369720500883, 'n_estimators': 49, 'min_child_samples': 10}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001937 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001728 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:50,930] Trial 43 finished with value: 0.7624937006908623 and parameters: {'num_leaves': 21, 'learning_rate': 0.0479494344727358, 'n_estimators': 47, 'min_child_samples': 10}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:51,098] Trial 44 finished with value: 1.344802304600175 and parameters: {'num_leaves': 21, 'learning_rate': 0.00010225989707116935, 'n_estimators': 49, 'min_child_samples': 17}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001763 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001803 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:51,238] Trial 45 finished with value: 0.9299914686769983 and parameters: {'num_leaves': 20, 'learning_rate': 0.031246358957501195, 'n_estimators': 35, 'min_child_samples': 12}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:51,408] Trial 46 finished with value: 0.6916882252573877 and parameters: {'num_leaves': 21, 'learning_rate': 0.07171119560576784, 'n_estimators': 48, 'min_child_samples': 8}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001755 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001753 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:51,569] Trial 47 finished with value: 1.3294592968971317 and parameters: {'num_leaves': 22, 'learning_rate': 0.00045320742067525577, 'n_estimators': 45, 'min_child_samples': 20}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n[I 2024-07-23 18:53:51,740] Trial 48 finished with value: 1.0163655840424775 and parameters: {'num_leaves': 20, 'learning_rate': 0.017032088698135495, 'n_estimators': 50, 'min_child_samples': 11}. Best is trial 22 with value: 0.6713366299663958.\n/tmp/ipykernel_33/1682860692.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 1e-1),\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001742 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001864 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"name":"stderr","text":"[I 2024-07-23 18:53:51,919] Trial 49 finished with value: 0.6874849029460537 and parameters: {'num_leaves': 26, 'learning_rate': 0.0938247596022786, 'n_estimators': 46, 'min_child_samples': 10}. Best is trial 22 with value: 0.6713366299663958.\n","output_type":"stream"}]},{"cell_type":"code","source":"best_params = study.best_params\nprint(f\" : {best_params}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:51.925103Z","iopub.execute_input":"2024-07-23T18:53:51.925483Z","iopub.status.idle":"2024-07-23T18:53:51.931403Z","shell.execute_reply.started":"2024-07-23T18:53:51.925454Z","shell.execute_reply":"2024-07-23T18:53:51.930253Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":" : {'num_leaves': 23, 'learning_rate': 0.09971633555235294, 'n_estimators': 50, 'min_child_samples': 9}\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model = lgb.LGBMRegressor(**best_params)\nbest_model.fit(X_train_preprocessed, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:51.934696Z","iopub.execute_input":"2024-07-23T18:53:51.935064Z","iopub.status.idle":"2024-07-23T18:53:52.082189Z","shell.execute_reply.started":"2024-07-23T18:53:51.935033Z","shell.execute_reply":"2024-07-23T18:53:52.081087Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001759 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2553\n[LightGBM] [Info] Number of data points in the train set: 8325, number of used features: 11\n[LightGBM] [Info] Start training from score 4.650150\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"LGBMRegressor(learning_rate=0.09971633555235294, min_child_samples=9,\n              n_estimators=50, num_leaves=23)","text/html":"<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.09971633555235294, min_child_samples=9,\n              n_estimators=50, num_leaves=23)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.09971633555235294, min_child_samples=9,\n              n_estimators=50, num_leaves=23)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_val_pred = best_model.predict(X_val_preprocessed)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.083386Z","iopub.execute_input":"2024-07-23T18:53:52.083712Z","iopub.status.idle":"2024-07-23T18:53:52.098247Z","shell.execute_reply.started":"2024-07-23T18:53:52.083684Z","shell.execute_reply":"2024-07-23T18:53:52.096925Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"val_median_absolute_error = median_absolute_error(y_val, y_val_pred)\nprint(f\"  : {val_median_absolute_error}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.099895Z","iopub.execute_input":"2024-07-23T18:53:52.100278Z","iopub.status.idle":"2024-07-23T18:53:52.106802Z","shell.execute_reply.started":"2024-07-23T18:53:52.100245Z","shell.execute_reply":"2024-07-23T18:53:52.105443Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"  : 0.6713366299663958\n","output_type":"stream"}]},{"cell_type":"code","source":"X_preprocessed = preprocessor.fit_transform(X)\nbest_model.fit(X_preprocessed, y)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.108337Z","iopub.execute_input":"2024-07-23T18:53:52.108768Z","iopub.status.idle":"2024-07-23T18:53:52.300647Z","shell.execute_reply.started":"2024-07-23T18:53:52.108729Z","shell.execute_reply":"2024-07-23T18:53:52.299519Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002216 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2570\n[LightGBM] [Info] Number of data points in the train set: 10407, number of used features: 11\n[LightGBM] [Info] Start training from score 4.647126\n","output_type":"stream"},{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"LGBMRegressor(learning_rate=0.09971633555235294, min_child_samples=9,\n              n_estimators=50, num_leaves=23)","text/html":"<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(learning_rate=0.09971633555235294, min_child_samples=9,\n              n_estimators=50, num_leaves=23)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(learning_rate=0.09971633555235294, min_child_samples=9,\n              n_estimators=50, num_leaves=23)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"preprocessor.fit(X)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.30223Z","iopub.execute_input":"2024-07-23T18:53:52.302648Z","iopub.status.idle":"2024-07-23T18:53:52.362404Z","shell.execute_reply.started":"2024-07-23T18:53:52.30261Z","shell.execute_reply":"2024-07-23T18:53:52.361201Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"ColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 Index(['allelectrons_Total', 'density_Total', 'allelectrons_Average',\n       'val_e_Average', 'atomicweight_Average', 'ionenergy_Average',\n       'el_neg_chi_Average', 'R_vdw_element_Average', 'R_cov_element_Average',\n       'zaratio_Average', 'density_Average'],\n      dtype='object')),\n                                ('cat',\n                                 Pipeline(steps=[('imputer',\n                                                  SimpleImputer(strategy='most_frequent')),\n                                                 ('onehot',\n                                                  OneHotEncoder(handle_unknown='ignore'))]),\n                                 Index([], dtype='object'))])","text/html":"<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n                                 Index([&#x27;allelectrons_Total&#x27;, &#x27;density_Total&#x27;, &#x27;allelectrons_Average&#x27;,\n       &#x27;val_e_Average&#x27;, &#x27;atomicweight_Average&#x27;, &#x27;ionenergy_Average&#x27;,\n       &#x27;el_neg_chi_Average&#x27;, &#x27;R_vdw_element_Average&#x27;, &#x27;R_cov_element_Average&#x27;,\n       &#x27;zaratio_Average&#x27;, &#x27;density_Average&#x27;],\n      dtype=&#x27;object&#x27;)),\n                                (&#x27;cat&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n                                                 (&#x27;onehot&#x27;,\n                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n                                 Index([], dtype=&#x27;object&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n                                 Index([&#x27;allelectrons_Total&#x27;, &#x27;density_Total&#x27;, &#x27;allelectrons_Average&#x27;,\n       &#x27;val_e_Average&#x27;, &#x27;atomicweight_Average&#x27;, &#x27;ionenergy_Average&#x27;,\n       &#x27;el_neg_chi_Average&#x27;, &#x27;R_vdw_element_Average&#x27;, &#x27;R_cov_element_Average&#x27;,\n       &#x27;zaratio_Average&#x27;, &#x27;density_Average&#x27;],\n      dtype=&#x27;object&#x27;)),\n                                (&#x27;cat&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n                                                 (&#x27;onehot&#x27;,\n                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n                                 Index([], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;allelectrons_Total&#x27;, &#x27;density_Total&#x27;, &#x27;allelectrons_Average&#x27;,\n       &#x27;val_e_Average&#x27;, &#x27;atomicweight_Average&#x27;, &#x27;ionenergy_Average&#x27;,\n       &#x27;el_neg_chi_Average&#x27;, &#x27;R_vdw_element_Average&#x27;, &#x27;R_cov_element_Average&#x27;,\n       &#x27;zaratio_Average&#x27;, &#x27;density_Average&#x27;],\n      dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>Index([], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"feature_importance = best_model.feature_importances_\nfeature_names = numeric_features.tolist() + preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features).tolist()\nimportance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': feature_importance\n})\n\nimportance_df = importance_df.sort_values(by='Importance', ascending=False)\nprint(importance_df.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.363616Z","iopub.execute_input":"2024-07-23T18:53:52.363939Z","iopub.status.idle":"2024-07-23T18:53:52.417921Z","shell.execute_reply.started":"2024-07-23T18:53:52.363909Z","shell.execute_reply":"2024-07-23T18:53:52.416138Z"},"trusted":true},"execution_count":86,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m----> 2\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m numeric_features\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m+\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_transformers_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43monehot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_names,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_importance\n\u001b[1;32m      6\u001b[0m })\n\u001b[1;32m      8\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m importance_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:1101\u001b[0m, in \u001b[0;36mOneHotEncoder.get_feature_names_out\u001b[0;34m(self, input_features)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m \n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;124;03m        Transformed feature names.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1101\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m     input_features \u001b[38;5;241m=\u001b[39m _check_feature_names_in(\u001b[38;5;28mself\u001b[39m, input_features)\n\u001b[1;32m   1103\u001b[0m     cats \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_transformed_categories(i)\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_)\n\u001b[1;32m   1106\u001b[0m     ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1385\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1386\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1387\u001b[0m     ]\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n","\u001b[0;31mNotFittedError\u001b[0m: This OneHotEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."],"ename":"NotFittedError","evalue":"This OneHotEncoder instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.","output_type":"error"}]},{"cell_type":"code","source":"plt.figure(figsize=(10, 8))\nplt.barh(importance_df['Feature'], importance_df['Importance'])\nplt.xlabel(\"Feature Importance\")\nplt.title(\"Feature Importance for Mineral Hardness Prediction\")\nplt.gca().invert_yaxis()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.419143Z","iopub.status.idle":"2024-07-23T18:53:52.419639Z","shell.execute_reply.started":"2024-07-23T18:53:52.419435Z","shell.execute_reply":"2024-07-23T18:53:52.419455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_data = test_data['id']\ntest_df = test_data.drop(columns=['id'])","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.421105Z","iopub.status.idle":"2024-07-23T18:53:52.421561Z","shell.execute_reply.started":"2024-07-23T18:53:52.421362Z","shell.execute_reply":"2024-07-23T18:53:52.421381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_preprocessed = preprocessor.transform(test_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.425344Z","iopub.status.idle":"2024-07-23T18:53:52.425803Z","shell.execute_reply.started":"2024-07-23T18:53:52.425604Z","shell.execute_reply":"2024-07-23T18:53:52.425623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_pred = best_model.predict(X_test_preprocessed)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.426847Z","iopub.status.idle":"2024-07-23T18:53:52.427295Z","shell.execute_reply.started":"2024-07-23T18:53:52.427081Z","shell.execute_reply":"2024-07-23T18:53:52.427098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({\n    'id': id_data,\n    'Hardness': y_test_pred\n})\n\nsubmission_file_path = '/kaggle/working/submission.csv'\nsubmission_df.to_csv(submission_file_path, index=False)\n\nprint(\"Submission file created at:\", submission_file_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.429191Z","iopub.status.idle":"2024-07-23T18:53:52.429647Z","shell.execute_reply.started":"2024-07-23T18:53:52.429452Z","shell.execute_reply":"2024-07-23T18:53:52.429472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_model = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('regressor', best_model)])\njoblib.dump(final_model, 'mineral_hardness_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.430776Z","iopub.status.idle":"2024-07-23T18:53:52.431197Z","shell.execute_reply.started":"2024-07-23T18:53:52.430982Z","shell.execute_reply":"2024-07-23T18:53:52.431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = joblib.load('mineral_hardness_model.pkl')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.432766Z","iopub.status.idle":"2024-07-23T18:53:52.433164Z","shell.execute_reply.started":"2024-07-23T18:53:52.43297Z","shell.execute_reply":"2024-07-23T18:53:52.432988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_data = test_df.iloc[:5, :]\nexample_data_preprocessed = preprocessor.transform(example_data)\nexample_pred = loaded_model.predict(example_data_preprocessed)\n\nprint(\"Predictions:\", example_pred)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.435108Z","iopub.status.idle":"2024-07-23T18:53:52.43554Z","shell.execute_reply.started":"2024-07-23T18:53:52.435352Z","shell.execute_reply":"2024-07-23T18:53:52.43537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_pred = best_model.predict(X_preprocessed)\ntrain_mae = median_absolute_error(y, y_train_pred)\ntest_mae = median_absolute_error(y_val, y_val_pred)\n\nmetrics_df = pd.DataFrame({\n    'Train': [train_mae],\n    'Test': [test_mae]\n}, index=['Median Absolute Error'])\n\nmetrics_df.plot(kind='bar', figsize=(8, 6))\nplt.title(\"Train vs Test Metrics\")\nplt.ylabel(\"Median Absolute Error\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-23T18:53:52.436872Z","iopub.status.idle":"2024-07-23T18:53:52.437285Z","shell.execute_reply.started":"2024-07-23T18:53:52.437076Z","shell.execute_reply":"2024-07-23T18:53:52.437093Z"},"trusted":true},"execution_count":null,"outputs":[]}]}